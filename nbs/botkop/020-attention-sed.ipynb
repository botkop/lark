{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f48d055-e268-4f98-b666-cb2bb86adfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b13303-1fe4-4c78-a36f-61489a41e576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n",
      "0.8.0a0+e4e171a\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio as ta\n",
    "import torchaudio.functional as taf\n",
    "import torchaudio.transforms as tat\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "print(torch.__version__)        \n",
    "print(ta.__version__)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "from typing import *\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from lark.config import Config\n",
    "from lark.learner import Learner, Backbone\n",
    "from lark.ops import Sig2Spec, MixedSig2Spec\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from lark.ops import f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723b789-2d11-49bc-9214-45b431479509",
   "metadata": {},
   "source": [
    "# attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ebb3ca9-1c95-40c9-9c95-9d71e18e4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd1bd58-a004-4812-beae-7231aa795bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "        sites=['COR', 'SSW'],\n",
    "        use_neptune=False,\n",
    "        n_epochs=10,\n",
    "        bs=64,\n",
    "        n_samples_per_label=100,\n",
    "        lr=1e-3,\n",
    "        model='tf_efficientnet_b0_ns',\n",
    "        scheduler='torch.optim.lr_scheduler.CosineAnnealingLR',\n",
    "        use_pink_noise=0.1,\n",
    "        use_recorded_noise=0.2,\n",
    "        use_overlays=True,\n",
    "        apply_filter=0.1,\n",
    "        seed=231,\n",
    "        n_workers=6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fd1b8f-4818-4923-ab70-daa1be974d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(cfg: Config, rank: int):\n",
    "    prep = MixedSig2Spec(cfg, rank)\n",
    "    backbone = Backbone('tf_efficientnet_b0_ns', pretrained=True)\n",
    "    embedding_size = 512\n",
    "    neck = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(0.3),\n",
    "        torch.nn.Linear(in_features=backbone.out_features, out_features=embedding_size, bias=True),\n",
    "        torch.nn.BatchNorm1d(embedding_size),\n",
    "        torch.nn.PReLU()\n",
    "    )\n",
    "    head = torch.nn.Linear(in_features=embedding_size, out_features=cfg.n_labels)\n",
    "    model = torch.nn.Sequential(prep, backbone, neck, head)\n",
    "    return model.to(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed76778-70b9-4005-a3aa-01a51b640fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(cfg, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70709b1b-fecc-4dc8-9b75-ce6c347b9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b0_ns-20210619-162543:0\n"
     ]
    }
   ],
   "source": [
    "lrn = Learner(\"tf_efficientnet_b0_ns\", cfg, rank, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b4f57-8e4f-4d42-b468-683c13812671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604d4413-c04c-4d79-882c-003b398ca423",
   "metadata": {},
   "source": [
    "# ogg 2 np: bad idea\n",
    "takes up a massive amount of disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26a2086d-f8ea-47e0-a7a4-fa469c214bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import glob\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c454fb7-b46b-4f5c-81bc-2a86c6756870",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"data/birdclef-2021/train_short_audio\"\n",
    "output_folder = \"data/birdclef-2021/train_short_audio.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19d80f37-94ae-4363-a6ba-81ffb347a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = glob.glob(f\"{input_folder}/*/*.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c91b90c-1234-47ec-92a6-c78058abf715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/birdclef-2021/train_short_audio/amepip/XC452810.ogg'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = input_files[0]\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14436e16-8de4-4130-a151-f9514d0ae9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ogg2np(fname, output_folder):\n",
    "    signal, _ = librosa.load(path=fname, sr=32000, mono=True)\n",
    "    tokens = fname.split('/')\n",
    "    basename = tokens[-1].split('.')[-2]\n",
    "    bird_name = tokens[-2]\n",
    "    output_dname = f\"{output_folder}/{bird_name}\"\n",
    "    pathlib.Path(output_dname).mkdir(parents=True, exist_ok=True)\n",
    "    output_fname = f\"{output_dname}/{basename}\"\n",
    "    np.save(output_fname, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f675d002-d7dd-4302-a423-ebd2fd527f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [ogg2np(f, output_folder) for f in input_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4115b8f0-136e-42be-b0c4-390f246d2fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346016"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(signal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lark",
   "language": "python",
   "name": "lark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
